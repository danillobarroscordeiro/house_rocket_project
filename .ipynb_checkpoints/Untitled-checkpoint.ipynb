{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3617a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T17:58:09.483573Z",
     "start_time": "2022-04-05T17:58:09.467929Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from datetime import datetime as dt\n",
    "from IPython.core.display import HTML\n",
    "import requests as r\n",
    "import plotly.express as px\n",
    "from geopy.geocoders import Nominatim\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from multiprocess import pool\n",
    "import time\n",
    "import get_data_address # multiprocessing file\n",
    "\n",
    "\n",
    "#functions\n",
    "\n",
    "\n",
    "def read_data(df):\n",
    "    data = pd.read_csv(df)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def selectionSlider_filter(df,column):\n",
    "    df_filter = widgets.SelectionSlider(description = 'Max avaliable date',options=df[column].sort_values().unique().tolist(),value=df[column].max()\n",
    "    ,min=df[column].min(),max=df[column].max(),disable=False, style=({'description_width':'initial'}), continuous_update=False)\n",
    "    return df_filter\n",
    "\n",
    "\n",
    "\n",
    "def update_dashboard(data, waterfront_filter, year_renovation_filter,date_avaliable_filter):\n",
    "    dashboard_filter = data.loc[((data['is_waterfront'] == waterfront_filter) |\n",
    "                       (data['yr_renovated'] >= str(year_renovation_filter)) |\n",
    "                       (data['date'] <= str(date_avaliable_filter))),:]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    specs = gridspec.GridSpec(ncols=2,nrows=2, figure=fig)\n",
    "    builtyear_meanprice_trendplot = fig.add_subplot(specs[1,:]) \n",
    "    dormitory_meanprice_barplot = fig.add_subplot(specs[0,1])\n",
    "    bedrooms_sumprice_barplot = fig.add_subplot(specs[0,0])\n",
    "    \n",
    "    realstate_groupby_builtyear_meanprice = dashboard_filter[['yr_built','price']].groupby('yr_built').mean().reset_index()\n",
    "    sns.lineplot(x='yr_built', y='price', data=realstate_groupby_builtyear_meanprice, ax=builtyear_meanprice_trendplot);\n",
    "    \n",
    "    realstate_groupby_dormitory_meanprice = dashboard_filter.loc[dashboard_filter['price'] != 0,['dormitory_type','price']].groupby('dormitory_type').mean().reset_index()\n",
    "    sns.barplot(x='dormitory_type', y='price', data=realstate_groupby_dormitory_meanprice, ax=dormitory_meanprice_barplot)\n",
    "    \n",
    "    realstate_groupby_bedrooms_sumprice = dashboard_filter.loc[dashboard_filter['price'] != 0,['bedrooms','price']].groupby('bedrooms').sum().reset_index()\n",
    "    sns.barplot(x='bedrooms', y='price', data=realstate_groupby_bedrooms_sumprice,ax=bedrooms_sumprice_barplot)\n",
    "    \n",
    "               \n",
    "\n",
    "    \n",
    "data = read_data(\"datasets/kc_house_data.csv\")\n",
    "data.rename({'price':'buying_price'}, axis=1)\n",
    "df = data[['price','zipcode']].groupby('zipcode').median().reset_index().rename({'price':'median_selling_price'}, axis=1)\n",
    "data = pd.merge(data,df, on='zipcode', how='inner')\n",
    "data['selling_price'] = data[['buying_price', 'median_selling_price']].apply(lambda x,y: x*1.1 if x > y\n",
    "                                                                     else x*1.3)\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date']).dt.strftime('%Y-%m-%d')\n",
    "data['season'] = pd.to_datetime(data['date']).dt.strftime('%m-%d').apply(lambda x: 'Summer' if '12-21' <= x < '03-21'\n",
    "                                                                         else 'Autunm' if '03-21' <= x < '06-21'\n",
    "                                                                         else 'Winter' if '06-21' <= x < '09-21'\n",
    "                                                                        else 'Spring' )data['house_age'] = np.where(data['yr_built'] >= 2014, 'new', 'old')\n",
    "\n",
    "\n",
    "filter_dormitory_type = [data['bedrooms'] <= 1, data['bedrooms'] == 2, data['bedrooms'] > 2]\n",
    "values_dormitory_type = ['studio', 'apartment', 'house']\n",
    "data['dormitory_type'] = np.select(filter_dormitory_type,values_dormitory_type)\n",
    "\n",
    "\n",
    "data['condition'] = data['condition'].astype(int)\n",
    "data['condition_type'] = data['condition'].apply(lambda x: 'bad' if x <= 2\n",
    "                                                   else 'regular' if (x ==3) | (x==4)\n",
    "                                                 else 'good')\n",
    "\n",
    "data['yr_built'] = pd.to_datetime(data['yr_built'], format= \"%Y\").dt.strftime('%Y')\n",
    "\n",
    "data['yr_renovated'] = (data['yr_renovated'].apply(lambda x: pd.to_datetime('1900-01-01', format = '%Y-%m-%d') if x == 0 else pd.to_datetime(x, format= \"%Y-%m-%d\"))).dt.strftime('%Y')\n",
    "\n",
    "data['is_waterfront'] = data['waterfront'].apply(lambda x: 'yes' if x == 1 else 'no')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lat_and_long = data[['lat', 'long']].apply(lambda x: [x['lat'],x['long']] , axis=1)\n",
    "#multi_processing = pool.Pool(3)\n",
    "#data['address'] = 'NA'\n",
    "#data['address'] = multi_processing.map(get_data_address.collect_geodata, lat_and_long.iteritems())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509100b",
   "metadata": {},
   "source": [
    "## 0.0 Importing libraries and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3244aea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T14:18:13.792492Z",
     "start_time": "2022-04-23T14:18:13.708835Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as scp\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from datetime import datetime as dt\n",
    "from IPython.core.display import HTML\n",
    "import requests as r\n",
    "import plotly.express as px\n",
    "from geopy.geocoders import Nominatim\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from multiprocess import pool\n",
    "import time\n",
    "import get_data_address # multiprocessing file\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    plt.style.use('bmh')\n",
    "    plt.rcParams['figure.figsize'] = (25,12)\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    #display(HTML('<style>.container (width:100%,)'))\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows= None\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    sns.set()\n",
    "\n",
    "def data_collect(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "def data_description(df):\n",
    "    print('Variables:\\n\\n{}'.format(df.dtypes), end='\\n\\n')\n",
    "    print('Number of rows {}'.format(df.shape[0]), end='\\n\\n')\n",
    "    print('Number of columns {}'.format(df.shape[1]), end='\\n\\n')\n",
    "    print('NA analysis'.format(end='\\n'))\n",
    "    for i in df.columns:\n",
    "        print('column {}: {} {}'.format(i,df[i].isna().any(), df[i].isna().sum()))\n",
    "        \n",
    "def outliers_analysis_q75(df,column):\n",
    "    df_result = df[df[column] >= 2*np.quantile(df[column], .75)].sort_values(ascending=False,by=[column])\n",
    "    return df_result\n",
    "\n",
    "def boxplot_analysis_quantitative(df,nrows,ncols):\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(30,20))\n",
    "    plt.subplots_adjust(left=0.1,bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)\n",
    "    \n",
    "    for column,axis in zip(df.select_dtypes(exclude=[object]).columns, axs.flatten()):\n",
    "        sns.boxplot(data=df.select_dtypes(exclude=[object]), y=column, ax=axis)\n",
    "        axis.tick_params(axis='y', labelsize=15)\n",
    "        axis.yaxis.label.set_fontsize(15)\n",
    "\n",
    "def quantile_30(x):\n",
    "    return x.quantile(0.3)\n",
    "def quantile_40(x):\n",
    "    return x.quantile(.4)\n",
    "def quantile_60(x):\n",
    "    return x.quantile(.6)\n",
    "def quantile_75(x):\n",
    "    return x.quantile(.75)\n",
    "\n",
    "\n",
    "def buying_propeties(df):\n",
    "    df2 = df[['buying_price','zipcode','condition_type']].groupby(['zipcode','condition_type'])\\\n",
    "    .agg(['median',quantile_30,quantile_40]).droplevel(0,axis=1).reset_index()\n",
    "    df = df.merge(df2, on=['zipcode','condition_type'])\n",
    "    for i in range(0,len(df)):\n",
    "        if df.loc[i,'condition_type'] == 'bad':\n",
    "            if df.loc[i,'buying_price'] <= df.loc[i,'quantile_40']:\n",
    "                df.loc[i,'decision'] = 'buy'\n",
    "            else:\n",
    "                df.loc[i,'decision'] = 'not buy'\n",
    "        elif df.loc[i,'condition_type'] == 'regular':\n",
    "            if df.loc[i,'buying_price'] <= df.loc[i,'quantile_40']:\n",
    "                df.loc[i,'decision'] = 'buy'\n",
    "            else:\n",
    "                df.loc[i,'decision'] = 'not buy'\n",
    "        elif df.loc[i,'condition_type'] == 'good':\n",
    "            if df.loc[i,'buying_price'] <= df.loc[i,'quantile_40']:\n",
    "                df.loc[i,'decision'] = 'buy'\n",
    "            else:\n",
    "                df.loc[i,'decision'] = 'not buy'\n",
    "    df = df.drop(['median','quantile_30','quantile_40'],axis=1)\n",
    "    return df\n",
    "\n",
    "def max_cost_improvement(df):\n",
    "    df2 = df.loc[df['condition_type'] == 'good',['buying_price','zipcode']].groupby('zipcode')\\\n",
    "    .agg(quantile_30)\\\n",
    "    .reset_index().rename({'buying_price':'quantile_30'},axis=1)\n",
    "    \n",
    "    df3 = df.loc[(df['condition_type'] == 'regular')\\\n",
    "    ,['buying_price','zipcode']].groupby('zipcode')\\\n",
    "    .agg([quantile_40]).reset_index().droplevel(0,axis=1)\\\n",
    "    .rename({'':'zipcode'},axis=1)\n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        if df2['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "            if (df.loc[i,'condition_type'] == 'bad') & (df.loc[i,'decision'] == 'buy') & \\\n",
    "                (pd.merge(df,df2,how='left', on='zipcode')\\\n",
    "                .loc[i,'quantile_30'] - df.loc[i,'buying_price'] >= 0):\n",
    "                    df.loc[i,'max_budget_improvement'] = pd.merge(df,df2,how='left', on='zipcode')\\\n",
    "                    .loc[i,'quantile_30'] - df.loc[i,'buying_price'] \n",
    "            else:\n",
    "                df.loc[i,'max_budget_improvement'] = 0\n",
    "        else:\n",
    "            if (df.loc[i,'condition_type'] == 'bad') & (df.loc[i,'decision'] == 'buy') & \\\n",
    "            (pd.merge(df,df3,how='left', on='zipcode')\\\n",
    "            .loc[i,'quantile_40'] - df.loc[i,'buying_price'] >= 0):\n",
    "                    df.loc[i,'max_budget_improvement'] = pd.merge(df,df3,how='left', on='zipcode')\\\n",
    "                    .loc[i,'quantile_40'] - df.loc[i,'buying_price']\n",
    "            else:\n",
    "                df.loc[i,'max_budget_improvement'] = 0\n",
    "                                \n",
    "    return df\n",
    "\n",
    "def suggested_selling_price(df):\n",
    "    df2 = df.loc[(df['condition_type'] == 'good')\\\n",
    "    ,['buying_price','zipcode']].groupby('zipcode')\\\n",
    "    .agg([quantile_40,'median',quantile_60]).reset_index().droplevel(0,axis=1).rename({'':'zipcode'},axis=1)\n",
    "    \n",
    "    df3 = df.loc[(df['condition_type'] == 'regular')\\\n",
    "    ,['buying_price','zipcode']].groupby('zipcode')\\\n",
    "    .agg([quantile_40,'median',quantile_60, quantile_75]).reset_index().droplevel(0,axis=1).rename({'':'zipcode'},axis=1)\n",
    "     \n",
    "    for i in range(0,len(df)):\n",
    "        if (df.loc[i,'condition_type'] == 'bad') & (df.loc[i,'decision'] == 'buy'):\n",
    "            if df2['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "                df.loc[i,\"suggested_selling_price\"] = pd.merge(df,df2, how='left',on='zipcode')\\\n",
    "                .loc[i,'median']\n",
    "            else:\n",
    "                df.loc[i,\"suggested_selling_price\"] = pd.merge(df,df3, on='zipcode')\\\n",
    "                .loc[i,'quantile_60']\n",
    "        elif (df.loc[i,'condition_type'] == 'regular') & (df.loc[i,'decision'] == 'buy'):\n",
    "            if df3['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "                df.loc[i,\"suggested_selling_price\"] = pd.merge(df,df3, how='left',on='zipcode')\\\n",
    "                .loc[i,'quantile_60']\n",
    "            else:\n",
    "                df.loc[i,\"suggested_selling_price\"] = pd.merge(df,df2, how='left',on='zipcode')\\\n",
    "                .loc[i,'quantile_40']\n",
    "        elif (df.loc[i,'condition_type'] == 'good') & (df.loc[i,'decision'] == 'buy'):\n",
    "            if df2['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "                df.loc[i,\"suggested_selling_price\"] = pd.merge(df,df2, how='left',on='zipcode')\\\n",
    "                .loc[i,'quantile_60']\n",
    "            else:\n",
    "                df.loc[i,\"suggested_selling_price\"] = pd.merge(df,df3, how='left',on='zipcode')\\\n",
    "                .loc[i,'quantile_75']\n",
    "        else:\n",
    "            df.loc[i,\"suggested_selling_price\"] = 0\n",
    "                \n",
    "    return df\n",
    "\n",
    "def min_selling_price(df):\n",
    "    df2 = df.loc[(df['condition_type'] == 'good')\\\n",
    "    ,['buying_price','zipcode']].groupby('zipcode')\\\n",
    "    .agg([quantile_40,'median',quantile_60]).reset_index().droplevel(0,axis=1).rename({'':'zipcode'},axis=1)\n",
    "    \n",
    "    df3 = df.loc[(df['condition_type'] == 'regular')\\\n",
    "    ,['buying_price','zipcode']].groupby('zipcode')\\\n",
    "    .agg([quantile_40,'median',quantile_60]).reset_index().droplevel(0,axis=1).rename({'':'zipcode'},axis=1)\n",
    "      \n",
    "    for i in range(0,len(df)):\n",
    "        if (df.loc[i,'condition_type'] == 'bad') & (df.loc[i,'decision'] == 'buy'):\n",
    "            if df2['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "                df.loc[i,\"min_selling_price\"] = pd.merge(df,df2, how='left',on='zipcode')\\\n",
    "                .loc[i,'quantile_40']\n",
    "            else:\n",
    "                df.loc[i,\"min_selling_price\"] = pd.merge(df,df3, on='zipcode')\\\n",
    "                .loc[i,'median']\n",
    "        elif (df.loc[i,'condition_type'] == 'regular') & (df.loc[i,'decision'] == 'buy'):\n",
    "            if df3['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "                df.loc[i,\"min_selling_price\"] = pd.merge(df,df3, how='left',on='zipcode')\\\n",
    "                .loc[i,'median']\n",
    "            else:\n",
    "                df.loc[i,\"min_selling_price\"] = pd.merge(df,df2, how='left',on='zipcode')\\\n",
    "                .loc[i,'quantile_40']\n",
    "        elif (df.loc[i,'condition_type'] == 'good') & (df.loc[i,'decision'] == 'buy'):\n",
    "            if df2['zipcode'].isin([df['zipcode'][i]]).any():\n",
    "                df.loc[i,\"min_selling_price\"] = pd.merge(df,df2, how='left',on='zipcode').loc[i,'median']\n",
    "            else:\n",
    "                df.loc[i,\"min_selling_price\"] = pd.merge(df,df3, how='left',on='zipcode').loc[i,'quantile_60']\n",
    "        else:\n",
    "            df.loc[i,\"min_selling_price\"] = 0\n",
    "                \n",
    "    return df\n",
    "\n",
    "def profits(df):\n",
    "    for i in range(0,len(df)):\n",
    "        if (df.loc[i,'decision'] == 'buy') & \\\n",
    "        (df.loc[i,'min_selling_price'] - df.loc[i,'buying_price'] > 0):\n",
    "            df.loc[i,'min_profit'] = df.loc[i,'min_selling_price'] - df.loc[i,'buying_price']\n",
    "            df.loc[i,'expected_profit'] = df.loc[i,'suggested_selling_price'] - df.loc[i,'buying_price']\n",
    "        else:\n",
    "            df.loc[i,'min_profit'] = 0\n",
    "            df.loc[i,'expected_profit'] = 0\n",
    "    return df.sort_values(by='expected_profit',ascending=False)\n",
    "\n",
    "def data_transform(df):\n",
    "    df['condition'] = df['condition'].astype(int)\n",
    "    df['price'] = df['price'].astype(float)\n",
    "    df['sqft_living'] = df['sqft_living'].astype(float)\n",
    "    df['sqft_lot'] = df['sqft_lot'].astype(float)\n",
    "    df['sqft_above'] = df['sqft_above'].astype(float)\n",
    "    df['sqft_basement'] = df['sqft_basement'].astype(float)\n",
    "    df['sqft_living15'] = df['sqft_living15'].astype(float)\n",
    "    df['sqft_lot15'] = df['sqft_lot15'].astype(float)\n",
    "    df['floors'] = df['floors'].apply(lambda x: 1 if 1 <= x < 2 else 2 if 2 <= x < 3 else 3).astype(str)\n",
    "    df['bathrooms'] = df['bathrooms'].apply(lambda x: round(x,0)).astype(int)\n",
    "    df2 = df[['price','zipcode']].groupby('zipcode').median().reset_index().rename({'price':'median_buying_price'}, axis=1)\n",
    "    df = pd.merge(df,df2, on='zipcode', how='inner')\n",
    "    df = df.rename({'price':'buying_price'},axis=1)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')\n",
    "    df['season'] = pd.to_datetime(df['date']).dt.strftime('%m-%d').apply(lambda x:\n",
    "                'Spring' if '03-21' <= x < '06-21'\n",
    "                else 'Summer' if '06-21' <= x < '09-21'                                                   \n",
    "                else 'Autunm' if '09-21' <= x < '12-21'\n",
    "                else 'Winter' )\n",
    "    \n",
    "    df['house_age'] = np.where(df['yr_built'] >= 2010, 'new', 'old')\n",
    "    df['yr_built'] = pd.to_datetime(df['yr_built'], format= \"%Y\").dt.strftime('%Y').astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    df['condition_type'] = df['condition'].apply(lambda x: 'bad' if x <= 2\n",
    "                                                else 'regular' if (x ==3) | (x==4)\n",
    "                                                else 'good')\n",
    "    \n",
    "    df['yr_renovated'] = (df['yr_renovated'].apply(\n",
    "    lambda x: pd.to_datetime('1900-01-01', format = '%Y-%m-%d') if x == 0 \n",
    "    else pd.to_datetime(x, format= \"%Y-%m-%d\"))).dt.strftime('%Y').astype(int)\n",
    "    df['is_renovated'] = df['yr_renovated'].apply(lambda x: 'no' if x == 1900 else 'yes')\n",
    "    df['is_waterfront'] = df['waterfront'].apply(lambda x: 'yes' if x == 1 else 'no')\n",
    "    df = df.drop(['view','grade','lat','long','condition','waterfront','yr_renovated'],axis=1)\n",
    "    \n",
    "    df = buying_propeties(df)\n",
    "    df = max_cost_improvement(df)\n",
    "    df = suggested_selling_price(df)\n",
    "    df = min_selling_price(df)\n",
    "    df = suggested_selling_price(df)\n",
    "    df = profits(df)\n",
    "    return df\n",
    " \n",
    "season_filter = widgets.Dropdown(options=['Spring','Summer','Autunm','Winter'], description='Choose season you want to sell the house:', value='Spring',\n",
    "style={'description_width':'initial'}, layout={'width': 'max-content'}, disabled=False)\n",
    "def data_load(df,season_filter):\n",
    "    df = df[df['season'] == season_filter]\n",
    "    return df.head(20)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#if __name__ = '__main__':\n",
    "#    data_raw = read_data('kc_house_data.csv')\n",
    "#    data_processing = data_transform(data_raw)\n",
    "#    data_load(data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add83e0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T14:21:00.421116Z",
     "start_time": "2022-04-23T14:18:18.002718Z"
    }
   },
   "outputs": [],
   "source": [
    "data_raw = data_collect('datasets/kc_house_data.csv')\n",
    "data_processing = data_transform(data_raw)\n",
    "widgets.interact(data_load, df=widgets.fixed(data_processing), season_filter=season_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1948e015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T23:24:42.019176Z",
     "start_time": "2022-04-24T23:24:41.968059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98031</td>\n",
       "      <td>POLYGON ((-122.21842 47.43750, -122.21896 47.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98032</td>\n",
       "      <td>MULTIPOLYGON (((-122.24187 47.44122, -122.2436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98033</td>\n",
       "      <td>POLYGON ((-122.20571 47.65170, -122.20571 47.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98034</td>\n",
       "      <td>POLYGON ((-122.17551 47.73706, -122.17551 47.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98030</td>\n",
       "      <td>POLYGON ((-122.16746 47.38549, -122.16746 47.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>98402</td>\n",
       "      <td>POLYGON ((-122.44279 47.26479, -122.44364 47.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>98403</td>\n",
       "      <td>POLYGON ((-122.44382 47.26617, -122.44384 47.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>98404</td>\n",
       "      <td>POLYGON ((-122.38900 47.23495, -122.39009 47.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>98405</td>\n",
       "      <td>POLYGON ((-122.44092 47.23639, -122.44463 47.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>98406</td>\n",
       "      <td>MULTIPOLYGON (((-122.52125 47.27121, -122.5237...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ZIPCODE                                           geometry\n",
       "0     98031  POLYGON ((-122.21842 47.43750, -122.21896 47.4...\n",
       "1     98032  MULTIPOLYGON (((-122.24187 47.44122, -122.2436...\n",
       "2     98033  POLYGON ((-122.20571 47.65170, -122.20571 47.6...\n",
       "3     98034  POLYGON ((-122.17551 47.73706, -122.17551 47.7...\n",
       "4     98030  POLYGON ((-122.16746 47.38549, -122.16746 47.3...\n",
       "..      ...                                                ...\n",
       "199   98402  POLYGON ((-122.44279 47.26479, -122.44364 47.2...\n",
       "200   98403  POLYGON ((-122.44382 47.26617, -122.44384 47.2...\n",
       "201   98404  POLYGON ((-122.38900 47.23495, -122.39009 47.2...\n",
       "202   98405  POLYGON ((-122.44092 47.23639, -122.44463 47.2...\n",
       "203   98406  MULTIPOLYGON (((-122.52125 47.27121, -122.5237...\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['geometry'] = geofile['geometry'].apply(lambda x: x if geofile.loc[geofile['ZIPCODE'] == x,'ZIPCODE']/\n",
    "                                          .isin(df['ZIPCODE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fa91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geofile[geofile['ZIPCODE'] == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b4743c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T23:24:24.082210Z",
     "start_time": "2022-04-24T23:24:24.069850Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26844/378347931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeofile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZIPCODE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ZIPCODE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/curso_python_zero_ao_ds/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9337\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9339\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   9340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9341\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/curso_python_zero_ao_ds/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 107\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/curso_python_zero_ao_ds/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/curso_python_zero_ao_ds/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m                 ):\n\u001b[0;32m-> 1257\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "d.merge(geofile[['ZIPCODE','geometry']], on='ZIPCODE', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ada76",
   "metadata": {},
   "source": [
    "# 1.0 Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d29c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T22:51:39.082280Z",
     "start_time": "2022-03-29T22:51:39.080002Z"
    }
   },
   "source": [
    "## 1.1 Data describing and analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d15d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:29:40.656823Z",
     "start_time": "2022-04-19T10:29:40.617021Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data_collect(\"datasets/kc_house_data.csv\")\n",
    "df = data.copy()\n",
    "data_description(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15aec201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:47:37.445503Z",
     "start_time": "2022-04-19T10:47:37.432087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>buying_price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>median_buying_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-122.3</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "      <td>278277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4060000240</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>205425.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>880.0</td>\n",
       "      <td>6780.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1945</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>6780.0</td>\n",
       "      <td>278277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4058801670</td>\n",
       "      <td>20140717T000000</td>\n",
       "      <td>445000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>8201.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-122.2</td>\n",
       "      <td>2660.0</td>\n",
       "      <td>8712.0</td>\n",
       "      <td>278277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2976800796</td>\n",
       "      <td>20140925T000000</td>\n",
       "      <td>236000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>5898.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-122.3</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>7619.0</td>\n",
       "      <td>278277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6874200960</td>\n",
       "      <td>20150227T000000</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>860.0</td>\n",
       "      <td>5265.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1931</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-122.3</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>8775.0</td>\n",
       "      <td>278277.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date  buying_price  bedrooms  bathrooms  \\\n",
       "0  7129300520  20141013T000000      221900.0         3          1   \n",
       "1  4060000240  20140623T000000      205425.0         2          1   \n",
       "2  4058801670  20140717T000000      445000.0         3          2   \n",
       "3  2976800796  20140925T000000      236000.0         3          1   \n",
       "4  6874200960  20150227T000000      170000.0         2          1   \n",
       "\n",
       "   sqft_living  sqft_lot floors  waterfront  view  ...  sqft_above  \\\n",
       "0       1180.0    5650.0      1           0     0  ...      1180.0   \n",
       "1        880.0    6780.0      1           0     0  ...       880.0   \n",
       "2       2100.0    8201.0      1           0     2  ...      1620.0   \n",
       "3       1300.0    5898.0      1           0     0  ...      1300.0   \n",
       "4        860.0    5265.0      1           0     0  ...       860.0   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode  lat   long  sqft_living15  \\\n",
       "0            0.0      1955             0    98178 47.5 -122.3         1340.0   \n",
       "1            0.0      1945             0    98178 47.5 -122.2         1190.0   \n",
       "2          480.0      1967             0    98178 47.5 -122.2         2660.0   \n",
       "3            0.0      1961             0    98178 47.5 -122.3         1320.0   \n",
       "4            0.0      1931             0    98178 47.5 -122.3         1650.0   \n",
       "\n",
       "   sqft_lot15  median_buying_price  \n",
       "0      5650.0             278277.0  \n",
       "1      6780.0             278277.0  \n",
       "2      8712.0             278277.0  \n",
       "3      7619.0             278277.0  \n",
       "4      8775.0             278277.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370d111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T19:04:15.030296Z",
     "start_time": "2022-04-02T19:04:14.995656Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe(exclude=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2482a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T10:17:31.969962Z",
     "start_time": "2022-04-18T10:17:31.926597Z"
    }
   },
   "outputs": [],
   "source": [
    "df['condition'] = df['condition'].astype(int)\n",
    "df['price'] = df['price'].astype(float)\n",
    "df['sqft_living'] = df['sqft_living'].astype(float)\n",
    "df['sqft_lot'] = df['sqft_lot'].astype(float)\n",
    "df['sqft_above'] = df['sqft_above'].astype(float)\n",
    "df['sqft_basement'] = df['sqft_basement'].astype(float)\n",
    "df['sqft_living15'] = df['sqft_living15'].astype(float)\n",
    "df['sqft_lot15'] = df['sqft_lot15'].astype(float)\n",
    "df['floors'] = df['floors'].apply(lambda x: 1 if 1 <= x < 2 else 2 if 2 <= x < 3 else 3).astype(str)\n",
    "df['bathrooms'] = df['bathrooms'].apply(lambda x: round(x,0)).astype(int)\n",
    "df = df.drop(['lat','long','grade'],axis=1)\n",
    "df = df.rename({'price':'selling_price'}, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3ced4",
   "metadata": {},
   "source": [
    "#### bedrooms\n",
    "There is a house with 33 bedrooms. Probably a typing error\n",
    "\n",
    "#### bathrooms\n",
    "In this columns there are decimal numbers, which does not make sense.\n",
    "\n",
    "#### sqft_lot\n",
    "There is a house with a huge lot (1651359 square feet). Probably another typing error.\n",
    "\n",
    "#### floors\n",
    "In this columns there are decimal numbers too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb160d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-03T19:47:02.380822Z",
     "start_time": "2022-04-03T19:47:01.603249Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "boxplot_analysis(df[df.columns.difference(['id','zipcode','view','condition','waterfront', 'bedrooms', 'floors'])],3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654a062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T13:02:36.243649Z",
     "start_time": "2022-04-09T13:02:32.296200Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.pairplot(df[df.columns.difference(['id','zipcode'])].select_dtypes(include=([float])),\n",
    "            corner=True, diag_kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce041d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T19:12:17.042398Z",
     "start_time": "2022-04-05T19:12:15.541265Z"
    }
   },
   "outputs": [],
   "source": [
    "df_corr_pearson = df[df.columns.difference(['id','zipcode'])].select_dtypes(include=([float,int])).corr()\n",
    "df_corr_pearson = df_corr_pearson.reindex(['selling_price'] + list([a for a in df_corr_pearson.columns if a != 'selling_price']), columns=(['selling_price'] + list([a for a in df_corr_pearson.columns if a != 'selling_price']) ))\n",
    "mask_pearson = np.triu(np.ones_like(df_corr_pearson\n",
    ", dtype=bool))\n",
    "\n",
    "df_corr_kendall = df[df.columns.difference(['id','zipcode'])].select_dtypes(include=([float,int])).corr('kendall')\n",
    "df_corr_kendall = df_corr_kendall.reindex(['selling_price'] + list([a for a in df_corr_kendall.columns if a != 'selling_price']), columns=(['selling_price'] + list([a for a in df_corr_kendall.columns if a != 'selling_price']) ))\n",
    "mask_kendall = np.triu(np.ones_like(df_corr_kendall\n",
    ", dtype=bool))\n",
    "\n",
    "plt.rcParams.update({'figure.subplot.hspace':.9})\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\", font_scale=2)\n",
    "fig = plt.figure(figsize=(35,25))\n",
    "specs = gridspec.GridSpec(ncols=1,nrows=2, figure=fig)\n",
    "pearson_corr = fig.add_subplot(specs[0,0])\n",
    "kendall_corr = fig.add_subplot(specs[1,0])\n",
    "pearson_corr.set_title('Pearson\\'s Correlation', fontsize=35)\n",
    "kendall_corr.set_title('Kendall\\'s Correlation', fontsize=35)\n",
    "pearson_corr.set_yticklabels(pearson_corr.get_yticklabels(), fontsize=30)\n",
    "kendall_corr.set_yticklabels(kendall_corr.get_yticklabels(), fontsize=30)\n",
    "\n",
    "sns.heatmap(df_corr_pearson,\n",
    "annot=True, cmap=\"GnBu\", linecolor='w', mask=mask_pearson, ax=pearson_corr);\n",
    "sns.heatmap(df_corr_kendall,\n",
    "    annot=True, cmap=\"GnBu\", linecolor='w', mask=mask_kendall, ax=kendall_corr,);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f77c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T23:19:17.508920Z",
     "start_time": "2022-03-28T23:19:17.505133Z"
    }
   },
   "source": [
    "## 1.2 Analysing/Editing/Excluding Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0b6d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T10:19:23.546428Z",
     "start_time": "2022-04-16T10:19:23.541904Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['bedrooms'] >= 2*np.quantile(df['bedrooms'], .75)]\n",
    "df['bedrooms'] = df['bedrooms'].replace(33,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9c799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T20:56:17.140641Z",
     "start_time": "2022-04-15T20:56:17.134398Z"
    }
   },
   "outputs": [],
   "source": [
    "outliers_analysis_q75(df,'sqft_lot')\n",
    "df['sqft_lot'] = df['sqft_lot'].replace(1651359, 425581)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743546aa",
   "metadata": {},
   "source": [
    "## 1.3 Transforming and creating variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78abf44",
   "metadata": {},
   "source": [
    "#### Creating the median selling price by zip code\n",
    "#### Creating the season columns based on data, as there is a sasonality in house prices\n",
    "#### Creating 'house age' columns with 'old' and 'new outcomes\n",
    "#### Creating 'condition' column with  'good', 'bad and 'regular' score\n",
    "#### Creating 'is renovated'  column with 'yes' and 'no outcomes\n",
    "#### Creating  'renovation year' classification\n",
    "#### Creating  'is waterfront column' with 'yes' and 'no' outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47966254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-18T10:17:40.916094Z",
     "start_time": "2022-04-18T10:17:38.906008Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df[['selling_price','zipcode']].groupby('zipcode').median().reset_index().rename({'selling_price':'median_selling_price'}, axis=1)\n",
    "df = pd.merge(df,df2, on='zipcode', how='inner')\n",
    "#df['selling_price'] = df.apply(lambda x: x['buying_price']*1.1 if x['buying_price'] > x['median_selling_price']\n",
    " #                                                                else x['buying_price']*1.3, axis=1)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')\n",
    "df['season'] = pd.to_datetime(df['date']).dt.strftime('%m-%d').apply(lambda x:\n",
    "                'Spring' if '03-21' <= x < '06-21'\n",
    "                else 'Summer' if '06-21' <= x < '09-21'                                                   \n",
    "                else 'Autunm' if '09-21' <= x < '12-21'\n",
    "                else 'Winter' )\n",
    "\n",
    "df['house_age'] = np.where(df['yr_built'] >= 2010, 'new', 'old')\n",
    "df['yr_built'] = pd.to_datetime(df['yr_built'], format= \"%Y\").dt.strftime('%Y').astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df['condition_type'] = df['condition'].apply(lambda x: 'bad' if x <= 2\n",
    "                                                   else 'regular' if (x ==3) | (x==4)\n",
    "                                                 else 'good')\n",
    "\n",
    "df['yr_renovated'] = (df['yr_renovated'].apply(\n",
    "lambda x: pd.to_datetime('1900-01-01', format = '%Y-%m-%d') if x == 0 \n",
    "else pd.to_datetime(x, format= \"%Y-%m-%d\"))).dt.strftime('%Y').astype(int)\n",
    "df['is_renovated'] = df['yr_renovated'].apply(lambda x: 'no' if x == 1900 else 'yes')\n",
    "df['is_waterfront'] = df['waterfront'].apply(lambda x: 'yes' if x == 1 else 'no')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb4c0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T00:35:01.423848Z",
     "start_time": "2022-03-24T00:35:01.398259Z"
    }
   },
   "source": [
    "# 2.0 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36a740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T17:32:04.771434Z",
     "start_time": "2022-04-05T17:32:04.769092Z"
    }
   },
   "source": [
    "## 2.1 Categorical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37baf257",
   "metadata": {},
   "source": [
    "   ### 2.1.1 Buying prices by condition type (with hypothesis test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac33fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T18:46:39.462301Z",
     "start_time": "2022-04-09T18:46:39.233914Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.boxplot(data=df[df['selling_price'] < 2000000], y='selling_price', x='condition_type', order=['bad','regular','good']);\n",
    "print(df[['condition_type', 'selling_price']].groupby('condition_type').agg(\n",
    "    [quantile_30,quantile_40,'median',quantile_60]).reset_index())\n",
    "print('Krukal-Wallis Test:', 'p-values is {}'.format(scp.stats.kruskal(df.loc[df['condition_type'] == 'bad','selling_price'],\n",
    "                 df.loc[df['condition_type'] == 'regular','selling_price'],\n",
    "                 df.loc[df['condition_type'] == 'good','selling_price']).pvalue))\n",
    "print('Mann-Whitney Test betwenn bad and good condition selling price:', \n",
    "'p-values is {}'.format(scp.stats.mannwhitneyu(df.loc[df['condition_type'] == 'bad','selling_price'], \n",
    "                    df.loc[df['condition_type'] == 'good','selling_price'], alternative='less').pvalue))\n",
    "print('Mann-Whitney Test betwenn regular and good condition selling price:', \n",
    "'p-values is {}'.format(scp.stats.mannwhitneyu(df.loc[df['condition_type'] == 'regular','selling_price'], \n",
    "            df.loc[df['condition_type'] == 'good','selling_price'], alternative='less').pvalue))\n",
    "\n",
    "#Reject that medians are equal.\n",
    "\n",
    "#Suggestions: The difference between a bad and good condition properties is considerably high.\n",
    "#This way a suggestion is buying bad houses and reform them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861210a",
   "metadata": {},
   "source": [
    "### 2.1.2 Boxplot of selling prices by waterfront view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098ed71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T18:47:39.461522Z",
     "start_time": "2022-04-05T18:47:39.280237Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=df[df['selling_price'] < 2000000], y='selling_price', x='is_waterfront');\n",
    "df[['is_waterfront', 'selling_price']].groupby('is_waterfront').median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d759f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T19:10:44.067712Z",
     "start_time": "2022-04-04T19:10:44.065594Z"
    }
   },
   "source": [
    "### 2.1.3 Boxplot of selling prices by house_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5659f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T14:24:12.784200Z",
     "start_time": "2022-04-09T14:24:12.599595Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=df[df['selling_price'] < 2000000], y='selling_price', x='house_age');\n",
    "df[['house_age', 'selling_price']].groupby('house_age').median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c7ae2",
   "metadata": {},
   "source": [
    "### 2.1.4 Boxplot of selling prices by is_renovated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c1bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T14:24:35.584013Z",
     "start_time": "2022-04-09T14:24:35.406363Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.boxplot(data=df[df['selling_price'] < 2000000], y='selling_price', x='is_renovated');\n",
    "df[['is_renovated', 'selling_price']].groupby('is_renovated').median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b3fb8",
   "metadata": {},
   "source": [
    "### 2.1.5 Boxplot of selling prices by floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6c1ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T14:24:48.633686Z",
     "start_time": "2022-04-09T14:24:48.445942Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,10))\n",
    "sns.boxplot(data=df[df['selling_price'] < 2000000], y='selling_price', x='floors')\n",
    "\n",
    "df[['floors', 'selling_price']].groupby('floors').median().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2ee24",
   "metadata": {},
   "source": [
    "### 2.1.6 Boxplot of selling prices by season (with hypothesis tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bec08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T14:56:22.818237Z",
     "start_time": "2022-04-09T14:56:22.602978Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,10))\n",
    "plt.style.use('ggplot')\n",
    "season_order = ['Spring','Summer','Autunm','Winter']\n",
    "sns.boxplot(data=df[df['selling_price'] < 1500000], y='selling_price', x='season', order=season_order);\n",
    "print(df[['season', 'selling_price']].groupby('season').median().reset_index())\n",
    "\n",
    "\n",
    "print('Krukal-Wallis Test:', 'p-value is {}'.format(scp.stats.kruskal(df.loc[df['season'] == 'Summer','selling_price'],\n",
    "                 df.loc[df['season'] == 'Autunm','selling_price'],\n",
    "                 df.loc[df['season'] == 'Spring','selling_price'],\n",
    "                 df.loc[df['season'] == 'Winter','selling_price']).pvalue))\n",
    " \n",
    "print('Mann-Whitney Test betwenn Summer and Winter season selling price:', \n",
    "'p-value is {}'.format(scp.stats.mannwhitneyu(df.loc[df['season'] == 'Summer','selling_price'], \n",
    "           df.loc[df['season'] == 'Winter','selling_price'], alternative='greater').pvalue))\n",
    "\n",
    "print('Mann-Whitney Test betwenn Spring and Summer season selling price:', \n",
    "'p-value is {}'.format(scp.stats.mannwhitneyu(df.loc[df['season'] == 'Spring','selling_price'], \n",
    "           df.loc[df['season'] == 'Summer','selling_price'], alternative='greater').pvalue))\n",
    "\n",
    "print('Mann-Whitney Test betwenn Autunm and Winter season selling price:', \n",
    "'p-value is {}'.format(scp.stats.mannwhitneyu(df.loc[df['season'] == 'Autunm','selling_price'], \n",
    "           df.loc[df['season'] == 'Winter','selling_price'], alternative='greater').pvalue))\n",
    "\n",
    "\n",
    "\n",
    "#We can reject the hypothesis that the median of selling price by season is not equal.\n",
    "#Also, post hoc comparisons between two seasons confirms that in fact are not equal, except\n",
    "#in autunm and winter. On theses seasons, we cannot reject the hypothesis that selling prices\n",
    "#median is equal.\n",
    "#The season with most median prices is spring.\n",
    "#A suggestion is buying houses on winter or autunm and sell them on spring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd299e8f",
   "metadata": {},
   "source": [
    "## 2.2 Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8ed86",
   "metadata": {},
   "source": [
    "### 2.2.1 Properties in good condition with 3 floors is 20% more expensive, on median, than regular condition properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657972fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T14:03:36.020108Z",
     "start_time": "2022-04-09T14:03:35.913166Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_floors = df[['floors', 'selling_price','condition_type']].groupby(['floors','condition_type']).median().reset_index()\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.style.use('ggplot')\n",
    "condition_order = ['bad', 'regular','good']\n",
    "sns.barplot(x='floors', y='selling_price',hue='condition_type',hue_order=condition_order, data=df_floors);\n",
    "df_floors\n",
    "#True. In fact, good condition selling price median is almost twice higher than\n",
    "#regular condition median selling price. Which means there is a great gap which one can spend money\n",
    "#in making improvements in regular properties to sell them as good ones. As they are regular,\n",
    "#those costs would not be much. However, the profit that a company could get is considerably high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3156ad",
   "metadata": {},
   "source": [
    "### 2.2.2 Properties which are in good and regular condition and was renovated is 20% more expensive, on median, than regular or good condition properties which was not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86237b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T21:25:37.971791Z",
     "start_time": "2022-04-06T21:25:37.864942Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_renovated = df.loc[(df['condition_type'] == 'regular') | (df['condition_type'] == 'good'),['is_renovated','selling_price', 'condition_type']].groupby(['is_renovated','condition_type']).median().reset_index()\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.style.use('ggplot')\n",
    "condition_order = ['regular','good']\n",
    "sns.barplot(x='is_renovated', y='selling_price', data=df_renovated, hue='condition_type',\n",
    "            hue_order=condition_order);\n",
    "df_renovated\n",
    "\n",
    "#True. In fact, renovated good contition properties are 26% more expensive than the not renovated ones. This means\n",
    "#that the company could acquire some non renovated houses, make some improvements on them that cost at most 13% of their\n",
    "#selling price, for instance. After that, selling them for 25% more than their selling price. Doing that they could\n",
    "#make good profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9a3c5",
   "metadata": {},
   "source": [
    "### 2.2.3 New houses without renovation is 15% more expensive, on median, than old renovated houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee2814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T20:00:30.222518Z",
     "start_time": "2022-04-04T20:00:30.118096Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new_houses = df.loc[((df['is_renovated'] == 'no') & (df['house_age'] == 'new')) \n",
    "    | ((df['is_renovated'] == 'yes') & (df['house_age'] == 'old')),['selling_price', 'house_age']].groupby('house_age').median().reset_index()\n",
    "df_new_houses['house_age'] = df_new_houses['house_age'].replace({'new': 'new without renovation','old': 'old with renovation'})\n",
    "df_new_houses = df_new_houses.rename({'house_age': 'condition_house'}, axis=1)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.style.use('ggplot')\n",
    "sns.barplot(x='condition_house', y='selling_price', data=df_new_houses);\n",
    "df_new_houses\n",
    "\n",
    "#False. Old renovation houses seems to be more worthy than new houses who has not been made improvements by approximately 10%.\n",
    "#A house is considered new when it was built at least at 2010. It confirms that there are good opportunities in getting\n",
    "#a old house for a lower price, making improvements on them and selling them with a higher price than new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ebc7b4",
   "metadata": {},
   "source": [
    "### 2.2.4 Properties prices on spring is 15% higher than prices on summer, on median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e19902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T17:16:43.855429Z",
     "start_time": "2022-04-09T17:16:43.781048Z"
    }
   },
   "outputs": [],
   "source": [
    "df_season_spring_summer = df.loc[(df['season'] == 'Spring') | (df['season'] == 'Summer'),['season','selling_price']].groupby('season').median().reset_index()\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.style.use('ggplot')\n",
    "season_order = ['Summer','Spring']\n",
    "sns.barplot(x='season', y='selling_price', data=df_season_spring_summer, order=season_order);\n",
    "print(df_season_spring_summer,'\\n' \n",
    "'Percentual difference between median spring prices and median autunm prices is {}%'.format(round((df_season_spring_summer.values[0][1]\n",
    " - df_season_spring_summer.values[1][1])/df_season_spring_summer.values[0][1]*100,2)))\n",
    "\n",
    "#False. Actually is approximately 4% higher than summer median.\n",
    "#This could happen due to high demand after winter season. These season should have the\n",
    "#highest company buying prices. The company could consider that there is no differences in prices\n",
    "#between theses season and selling properties with same price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63622ba2",
   "metadata": {},
   "source": [
    "### 2.2.5 Properties prices on Spring is 10% higher than prices on autunm, on median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b0991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-09T15:41:14.014708Z",
     "start_time": "2022-04-09T15:41:13.946870Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_season_spring_autunm= df.loc[(df['season'] == 'Spring') | (df['season'] == 'Autunm'),['season','selling_price']].groupby('season').median().reset_index()\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.style.use('ggplot')\n",
    "season_order = ['Autunm','Spring']\n",
    "sns.barplot(x='season', y='selling_price', data=df_season_spring_autunm, order=season_order);\n",
    "print(df_season_spring_autunm,'\\n' \n",
    "'Percentual difference between median spring prices and median autunm prices is {}%'.format(round((df_season_spring_autunm.values[1][1]\n",
    " - df_season_spring_autunm.values[0][1])/df_season_spring_autunm.values[0][1]*100,2)))\n",
    "\n",
    "#False. In fact, is approximately 7,32% higher than autumn median. Here, a suggestion is \n",
    "#putting different selling prices for these seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638c37f",
   "metadata": {},
   "source": [
    "## 3.0 Which properties company should buy and for what price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d25db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T18:54:05.588084Z",
     "start_time": "2022-04-16T18:54:05.580300Z"
    }
   },
   "source": [
    "Considering that company could buy properties to reform them. We propose the following:\n",
    "\n",
    "#An ideia is buying bad condition houses that worth at most the 40 decile of buying prices of its\n",
    "#region. The total spend money (house price + reform budget) should be at most the\n",
    "30 decile of good houses of its region.\n",
    "\n",
    "If a house has a regular or good condition,however, company can buy propeties that has\n",
    "#price at most the 40 decile of regular or good condition house prices of its region. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fa0d8",
   "metadata": {},
   "source": [
    "## 4.0 How much the company could spend to making improvements in each bad properties?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12935c70",
   "metadata": {},
   "source": [
    "For bad condition properties:\n",
    "\n",
    "The company could spend at most the 30 decile of good condition properties of its region  -\n",
    "property selling price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c02ae1",
   "metadata": {},
   "source": [
    "## 5.0 After buy them, when to sell them and for how much?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a7cb0",
   "metadata": {},
   "source": [
    "Considering two scenarios:\n",
    "\n",
    "Minimum selling price:\n",
    "Would be the 40th decile of good condition properties buying price of its region, considering\n",
    "the season which the house will be selled as well, in case of bad condition properties.\n",
    "\n",
    "Would be the median of regular condition properties buying price of its region,considering\n",
    "the season which the house will be selled as well, in case of regular condition properties.\n",
    "\n",
    "Would be the median of good condition properties buying price of its region,considering\n",
    "the season which the house will be selled as well, in case of regular condition properties.\n",
    "\n",
    "\n",
    "Suggested selling price:\n",
    "For bad condition properties which were reformed:\n",
    "\n",
    "Would be the median of good condition properties buying prices of its region, considering\n",
    "the season which the house will be selled as well.\n",
    "In case there is no good condition properties on sold in some region, will be considered the 60th decile of regular condition properties buying prices of this region.\n",
    "\n",
    "\n",
    "For regular condition properties:\n",
    "\n",
    "Would be the 60th decile of regular condition properties buying price of its region, considering the season which the house will be selled as well. \n",
    "In case there is no regular condition properties on sold in some region, will be\n",
    "considered the 40th decile of good condition properties buying prices of this region.\n",
    " \n",
    " \n",
    "For good condition properties:\n",
    " \n",
    "Would be the 60th decile of good condition properties buying price of its region, considering\n",
    "the season which the house will be selled as well, in case of good condition properties. In case there is no good condition properties on sold in some region, will be\n",
    "considered the 75th quantile of regular condition properties buying prices of this region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280b3d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T14:32:23.439850Z",
     "start_time": "2022-04-10T14:32:23.437497Z"
    }
   },
   "source": [
    "## 6.0 How much profit company would make per house selled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d2775",
   "metadata": {},
   "source": [
    "Considering two scenarions:\n",
    "\n",
    "Minimum profit\n",
    "The difference between the minimum selling price minus buying price of that property.\n",
    "\n",
    "Expected profit\n",
    "The difference between the suggested selling price minus buying price of that property."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
